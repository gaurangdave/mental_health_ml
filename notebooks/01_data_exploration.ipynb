{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62eaa3ff",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4c3a2",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "* We'll start with Preprocessing categorical values and applying some standard data cleaning steps.\n",
    "    * Remove spaces.\n",
    "    * Convert to lower case.\n",
    "    * Unicode normalization.\n",
    "    * Handling missing/unknown categories.\n",
    "* We'll create `scikit-learn` pipelines that we can reusing during training. \n",
    "* We'll do the same for numerical data as well. \n",
    "* At the end of this notebook we'll have list of data preparation steps needed to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a01634",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b6192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a161244a",
   "metadata": {},
   "source": [
    "## Read Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "216152c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## root directory for all data files\n",
    "data_dir = Path(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2cafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(Path(data_dir,\"X_train.csv\"))\n",
    "y_train = pd.read_csv(Path(data_dir,\"y_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deeeb842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22320, 16), (22320, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfd3f9",
   "metadata": {},
   "source": [
    "## Preprocessing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc37660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "city                 object\n",
       "profession           object\n",
       "sleep_duration       object\n",
       "dietary_habits       object\n",
       "degree               object\n",
       "suicidal_thoughts    object\n",
       "family_history       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets list the categorical columns\n",
    "X_train.select_dtypes(include=[\"object\"]).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0edfed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "profession",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sleep_duration",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dietary_habits",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "degree",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "suicidal_thoughts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "family_history",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ec89b212-61d5-4b2e-aa5d-9f777dab1ba5",
       "rows": [
        [
         "0",
         "Male",
         "Jaipur",
         "Student",
         "'7-8 hours'",
         "Moderate",
         "'Class 12'",
         "Yes",
         "No"
        ],
        [
         "1",
         "Male",
         "Vadodara",
         "Student",
         "'7-8 hours'",
         "Moderate",
         "B.Arch",
         "No",
         "Yes"
        ],
        [
         "2",
         "Male",
         "Ahmedabad",
         "Student",
         "'7-8 hours'",
         "Unhealthy",
         "M.Ed",
         "Yes",
         "Yes"
        ],
        [
         "3",
         "Male",
         "Bhopal",
         "Student",
         "'7-8 hours'",
         "Moderate",
         "B.Com",
         "Yes",
         "No"
        ],
        [
         "4",
         "Male",
         "Patna",
         "Student",
         "'5-6 hours'",
         "Unhealthy",
         "B.Com",
         "No",
         "No"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>profession</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>dietary_habits</th>\n",
       "      <th>degree</th>\n",
       "      <th>suicidal_thoughts</th>\n",
       "      <th>family_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Student</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>'Class 12'</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>Student</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Arch</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Student</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>M.Ed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Student</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Com</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Patna</td>\n",
       "      <td>Student</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>B.Com</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender       city profession sleep_duration dietary_habits      degree  \\\n",
       "0   Male     Jaipur    Student    '7-8 hours'       Moderate  'Class 12'   \n",
       "1   Male   Vadodara    Student    '7-8 hours'       Moderate      B.Arch   \n",
       "2   Male  Ahmedabad    Student    '7-8 hours'      Unhealthy        M.Ed   \n",
       "3   Male     Bhopal    Student    '7-8 hours'       Moderate       B.Com   \n",
       "4   Male      Patna    Student    '5-6 hours'      Unhealthy       B.Com   \n",
       "\n",
       "  suicidal_thoughts family_history  \n",
       "0               Yes             No  \n",
       "1                No            Yes  \n",
       "2               Yes            Yes  \n",
       "3               Yes             No  \n",
       "4                No             No  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets look at the data to make sure they are correctly typed as object\n",
    "X_train.select_dtypes(include=[\"object\"]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3022bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'city',\n",
       " 'profession',\n",
       " 'sleep_duration',\n",
       " 'dietary_habits',\n",
       " 'degree',\n",
       " 'suicidal_thoughts',\n",
       " 'family_history']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating column list for easier access\n",
    "category_columns = X_train.select_dtypes(include=[\"object\"]).dtypes.index.tolist()\n",
    "category_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f1017",
   "metadata": {},
   "source": [
    "### Default Changes\n",
    "* This section applies all the default changes to categorical data like, \n",
    "    * removing spaces, \n",
    "    * replacing empty string with unknown (we can use some kind of prediction algorithm here but for now unknown is good since there are no empty values. )\n",
    "    * lower case the values.\n",
    "    * Unicode normalizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed7fccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "city                 0\n",
       "profession           0\n",
       "sleep_duration       0\n",
       "dietary_habits       0\n",
       "degree               0\n",
       "suicidal_thoughts    0\n",
       "family_history       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets check for missing values\n",
    "X_train.select_dtypes(include=[\"object\"]).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019f154",
   "metadata": {},
   "source": [
    "Luckily there are no missing values but our training pipeline should have a step to fill missing values with \"unkonwn\" in case production data or test data has missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1f4a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Add this to pipeline\n",
    "X_train.select_dtypes(include=[\"object\"]).fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebefd93",
   "metadata": {},
   "source": [
    "Lets create pipelines to transform the data for easy exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce9e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pandas.api.types import is_string_dtype\n",
    "\n",
    "## creating functional transformers\n",
    "\n",
    "## fill na with Unknown\n",
    "def fill_empty_strings_fn(df, columns=None):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        ## TODO : Confirm if comparing with type object is correct. \n",
    "        if is_string_dtype(df_copy[col]):\n",
    "            df_copy[col] = df_copy[col].fillna(\"unknown\")\n",
    "    return df_copy\n",
    "\n",
    "## remove spaces\n",
    "def strip_spaces_fn(df, colmns=None):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        ## TODO : Confirm if comparing with type object is correct. \n",
    "        if is_string_dtype(df_copy[col]):\n",
    "            df_copy[col] = df_copy[col].str.strip()\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "\n",
    "def to_lower_case_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        ## TODO : Confirm if comparing with type object is correct. \n",
    "        if is_string_dtype(df_copy[col]):\n",
    "            df_copy[col] = df_copy[col].str.lower()\n",
    "    return df_copy\n",
    "\n",
    "def normalize_unicode_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        ## TODO : Confirm if comparing with type object is correct. \n",
    "        if is_string_dtype(df_copy[col]):\n",
    "            df_copy[col] = df_copy[col].map(lambda ct: unicodedata.normalize(\"NFKD\",ct).encode(\"ascii\",\"ignore\").decode())\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "fill_empty_strings = FunctionTransformer(fill_empty_strings_fn,feature_names_out=\"one-to-one\")\n",
    "strip_spaces = FunctionTransformer(strip_spaces_fn,feature_names_out=\"one-to-one\")\n",
    "to_lower_case = FunctionTransformer(to_lower_case_fn,feature_names_out=\"one-to-one\")\n",
    "normalize_unicode = FunctionTransformer(normalize_unicode_fn, feature_names_out=\"one-to-one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece7c7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "profession",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sleep_duration",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dietary_habits",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "degree",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "suicidal_thoughts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "family_history",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cbe32402-36f2-4283-acac-e6d0e00fc62f",
       "rows": [
        [
         "0",
         "male",
         "jaipur",
         "student",
         "'7-8 hours'",
         "moderate",
         "'class 12'",
         "yes",
         "no"
        ],
        [
         "1",
         "male",
         "vadodara",
         "student",
         "'7-8 hours'",
         "moderate",
         "b.arch",
         "no",
         "yes"
        ],
        [
         "2",
         "male",
         "ahmedabad",
         "student",
         "'7-8 hours'",
         "unhealthy",
         "m.ed",
         "yes",
         "yes"
        ],
        [
         "3",
         "male",
         "bhopal",
         "student",
         "'7-8 hours'",
         "moderate",
         "b.com",
         "yes",
         "no"
        ],
        [
         "4",
         "male",
         "patna",
         "student",
         "'5-6 hours'",
         "unhealthy",
         "b.com",
         "no",
         "no"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>profession</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>dietary_habits</th>\n",
       "      <th>degree</th>\n",
       "      <th>suicidal_thoughts</th>\n",
       "      <th>family_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>jaipur</td>\n",
       "      <td>student</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>moderate</td>\n",
       "      <td>'class 12'</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>vadodara</td>\n",
       "      <td>student</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>moderate</td>\n",
       "      <td>b.arch</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>student</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>m.ed</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>bhopal</td>\n",
       "      <td>student</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>moderate</td>\n",
       "      <td>b.com</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>patna</td>\n",
       "      <td>student</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>b.com</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender       city profession sleep_duration dietary_habits      degree  \\\n",
       "0   male     jaipur    student    '7-8 hours'       moderate  'class 12'   \n",
       "1   male   vadodara    student    '7-8 hours'       moderate      b.arch   \n",
       "2   male  ahmedabad    student    '7-8 hours'      unhealthy        m.ed   \n",
       "3   male     bhopal    student    '7-8 hours'       moderate       b.com   \n",
       "4   male      patna    student    '5-6 hours'      unhealthy       b.com   \n",
       "\n",
       "  suicidal_thoughts family_history  \n",
       "0               yes             no  \n",
       "1                no            yes  \n",
       "2               yes            yes  \n",
       "3               yes             no  \n",
       "4                no             no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## in our use case pipeline would make more sense as we need to use output of one transformer in another. \n",
    "default_cat_pipeline = Pipeline([\n",
    "    (\"fill_empty_strings\", fill_empty_strings),\n",
    "    (\"strip_spaces\", strip_spaces),\n",
    "    (\"to_lower_case\", to_lower_case),\n",
    "    (\"normalize_unicode\", normalize_unicode)    \n",
    "], )\n",
    "\n",
    "## only run the pipeline on categorical data\n",
    "updated_categories = default_cat_pipeline.fit_transform(X_train.select_dtypes(include=[\"object\", \"string\"]))\n",
    "updated_categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f5e2c",
   "metadata": {},
   "source": [
    "### Preprocessing Gender Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4322eb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male      12437\n",
       "female     9883\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c317d",
   "metadata": {},
   "source": [
    "* Since the data is distributed between just 2 genders we can use `OneHotEncoder` to encode the data.\n",
    "* Lets also use this to explore how we'll design our design our data transformation implementation. We'll need a combination of Pipelines and ColumnTransformers to make it efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a264e83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['preprocessing_gender__gender_female',\n",
       "       'preprocessing_gender__gender_male'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "gender_pipeline = Pipeline([\n",
    "    (\"default_cat_pipeline\", default_cat_pipeline),\n",
    "    (\"encode_gender\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessing_gender = ColumnTransformer([\n",
    "    (\"preprocessing_gender\", gender_pipeline, [\"gender\"])\n",
    "])\n",
    "\n",
    "preprocessing_gender.fit_transform(X_train)\n",
    "preprocessing_gender.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7700b12b",
   "metadata": {},
   "source": [
    "* So this will be our plan going forward, we'll create column specific pipelines which will be a combination of default pipeline and column specific transformations and finally combine all pipeline into one clean \"preprocessing_pipeline\" column transformer. \n",
    "* For now we'll keep gender as it is for easier data exploration in next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd7a74",
   "metadata": {},
   "source": [
    "### Preprocessing Profession Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "592d236a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profession\n",
       "student                     22294\n",
       "architect                       6\n",
       "teacher                         4\n",
       "'digital marketer'              3\n",
       "'content writer'                2\n",
       "chef                            2\n",
       "doctor                          2\n",
       "pharmacist                      2\n",
       "manager                         1\n",
       "'educational consultant'        1\n",
       "lawyer                          1\n",
       "entrepreneur                    1\n",
       "'civil engineer'                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"profession\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf58af40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11648745519713263"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(updated_categories[updated_categories[\"profession\"] != 'student'].shape[0] / updated_categories.shape[0] ) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef8a09",
   "metadata": {},
   "source": [
    "* So majority of the profession are students, and we have less than 1% of non student instances.\n",
    "* Although this lack of variance will contribute very little to our classification, for now we'll create a pipeline to change value of every non-student to 'working' and then one-hot encode them. \n",
    "* This assumption might be wrong in test data or in production, but we'll handle it when we see new information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "899bb9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['preprocessing_profession__profession_student',\n",
       "       'preprocessing_profession__profession_working'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to map \"profession\" column values to 'student' and 'working'\n",
    "def map_working_profession_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy.loc[df_copy[\"profession\"] != 'student'] = 'working'\n",
    "    return df_copy\n",
    "\n",
    "map_working_profession = FunctionTransformer(map_working_profession_fn, feature_names_out=\"one-to-one\")\n",
    "\n",
    "profession_pipeline = Pipeline([\n",
    "    (\"default_cat_pipeline\", default_cat_pipeline),\n",
    "    (\"map_profession\", map_working_profession),\n",
    "    (\"encode_profession\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessing_profession = ColumnTransformer([\n",
    "    (\"preprocessing_profession\", profession_pipeline, [\"profession\"])\n",
    "])\n",
    "\n",
    "# we can uncomment this if we need pandas as output\n",
    "# preprocessing_profession.set_output(transform=\"pandas\")\n",
    "\n",
    "temp = preprocessing_profession.fit_transform(X_train)\n",
    "preprocessing_profession.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de084ebd",
   "metadata": {},
   "source": [
    "* Lets also update the train set for now, to help with data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5535023",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_categories.loc[updated_categories[\"profession\"] != 'student','profession'] = \"working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "852e5435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profession\n",
       "student    22294\n",
       "working       26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"profession\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e077fa23",
   "metadata": {},
   "source": [
    "### Preprocessing Sleep Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17280fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sleep_duration\n",
       "'less than 5 hours'    6646\n",
       "'7-8 hours'            5871\n",
       "'5-6 hours'            4963\n",
       "'more than 8 hours'    4825\n",
       "others                   15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"sleep_duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3fa7037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06720430107526883"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(updated_categories[updated_categories[\"sleep_duration\"] == 'others'].shape[0] / updated_categories.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9aa7ef",
   "metadata": {},
   "source": [
    "* Looking at the data I think its safe to merge 'others' with 'more than 8 hours'. \n",
    "* Here is the plan,\n",
    "    * We'll change the values to `lt_5`, `bt_7_8` and `gt_8` so less verbose values and column names. We might find more values in test or prod, but for now we'll assume these are the possible values. \n",
    "    * We'll merge `others` to `gt_8` since the sample size is very small.\n",
    "    * We'll either one hot encode the data or ordinal encoding depending on the algorithm we want to use\n",
    "* One more interesting thing that we missed earlier is that these strings have single quote in them, we'll need to strip them before processing anything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da4277e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sleep_duration_pipeline__sleep_duration'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function to rename and map the sleep duration category\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "def sleep_duration_cleanup_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"sleep_duration\"] = df[\"sleep_duration\"].str.strip(\"'\")\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "sleep_duration_cleanup = FunctionTransformer(\n",
    "    sleep_duration_cleanup_fn, feature_names_out=\"one-to-one\")\n",
    "\n",
    "\n",
    "def sleep_duration_mapping_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    # map 'less than 5 hours' to lt_5\n",
    "    df_copy.loc[df_copy[\"sleep_duration\"] ==\n",
    "                'less than 5 hours', 'sleep_duration'] = 'lt_5'\n",
    "    # map '5-6 hours' to bt_5_6\n",
    "    df_copy.loc[df_copy[\"sleep_duration\"] ==\n",
    "                '5-6 hours', 'sleep_duration'] = 'bt_5_6'\n",
    "    # map '7-8 hours' to bt_7_8\n",
    "    df_copy.loc[df_copy[\"sleep_duration\"] ==\n",
    "                '7-8 hours', 'sleep_duration'] = 'bt_7_8'\n",
    "    # more than 8 hours to gt_8\n",
    "    df_copy.loc[df_copy[\"sleep_duration\"] ==\n",
    "                'more than 8 hours', 'sleep_duration'] = 'gt_8'\n",
    "    # more than others to gt_8\n",
    "    df_copy.loc[df_copy[\"sleep_duration\"] ==\n",
    "                'others', 'sleep_duration'] = 'gt_8'\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "sleep_duration_mapping = FunctionTransformer(\n",
    "    sleep_duration_mapping_fn, feature_names_out=\"one-to-one\")\n",
    "\n",
    "\n",
    "def make_sleep_duration_pipeline_fn(encoding=\"onehot\"):\n",
    "    steps = [(\"default_cat_pipeline\", default_cat_pipeline),\n",
    "             (\"sleep_duration_cleanup\", sleep_duration_cleanup),\n",
    "             (\"sleep_duration_mapping\", sleep_duration_mapping)]\n",
    "\n",
    "    if encoding == \"onehot\":\n",
    "        steps.append((\"encoder\", OneHotEncoder(\n",
    "            sparse_output=False, handle_unknown=\"ignore\")))\n",
    "    elif encoding == \"ordinal\":\n",
    "        steps.append((\"encoder\", OrdinalEncoder(categories=[[\n",
    "            \"lt_5\", \"bt_5_6\", \"bt_7_8\", \"gt_8\"\n",
    "        ]], handle_unknown=\"use_encoded_value\", unknown_value=-1)))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid encoding type: choose 'onehot' or 'ordinal'\")\n",
    "    return Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "preprocesing_sleep_duration = ColumnTransformer([(\n",
    "    \"sleep_duration_pipeline\", make_sleep_duration_pipeline_fn(encoding=\"ordinal\"), [\n",
    "        \"sleep_duration\"]\n",
    ")])\n",
    "\n",
    "temp = preprocesing_sleep_duration.fit_transform(X_train)\n",
    "preprocesing_sleep_duration.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cbcf96",
   "metadata": {},
   "source": [
    "* Lets update our dataset with cleaned categorical values for easier data exploration later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0beef8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "profession",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sleep_duration",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dietary_habits",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "degree",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "suicidal_thoughts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "family_history",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "71320684-169e-4770-8085-b412b097af2f",
       "rows": [
        [
         "0",
         "male",
         "jaipur",
         "student",
         "bt_7_8",
         "moderate",
         "'class 12'",
         "yes",
         "no"
        ],
        [
         "1",
         "male",
         "vadodara",
         "student",
         "bt_7_8",
         "moderate",
         "b.arch",
         "no",
         "yes"
        ],
        [
         "2",
         "male",
         "ahmedabad",
         "student",
         "bt_7_8",
         "unhealthy",
         "m.ed",
         "yes",
         "yes"
        ],
        [
         "3",
         "male",
         "bhopal",
         "student",
         "bt_7_8",
         "moderate",
         "b.com",
         "yes",
         "no"
        ],
        [
         "4",
         "male",
         "patna",
         "student",
         "bt_5_6",
         "unhealthy",
         "b.com",
         "no",
         "no"
        ],
        [
         "5",
         "female",
         "kolkata",
         "student",
         "lt_5",
         "healthy",
         "m.ed",
         "no",
         "no"
        ],
        [
         "6",
         "male",
         "kanpur",
         "student",
         "bt_5_6",
         "healthy",
         "llb",
         "yes",
         "no"
        ],
        [
         "7",
         "male",
         "patna",
         "student",
         "gt_8",
         "unhealthy",
         "bca",
         "yes",
         "no"
        ],
        [
         "8",
         "male",
         "ghaziabad",
         "student",
         "bt_7_8",
         "unhealthy",
         "llb",
         "no",
         "no"
        ],
        [
         "9",
         "male",
         "bhopal",
         "student",
         "gt_8",
         "unhealthy",
         "b.arch",
         "no",
         "no"
        ],
        [
         "10",
         "male",
         "kalyan",
         "student",
         "gt_8",
         "unhealthy",
         "msc",
         "no",
         "no"
        ],
        [
         "11",
         "male",
         "pune",
         "student",
         "lt_5",
         "moderate",
         "mca",
         "yes",
         "no"
        ],
        [
         "12",
         "female",
         "jaipur",
         "student",
         "bt_5_6",
         "unhealthy",
         "b.arch",
         "no",
         "yes"
        ],
        [
         "13",
         "male",
         "pune",
         "student",
         "gt_8",
         "healthy",
         "b.pharm",
         "yes",
         "yes"
        ],
        [
         "14",
         "male",
         "srinagar",
         "student",
         "bt_5_6",
         "moderate",
         "'class 12'",
         "no",
         "yes"
        ],
        [
         "15",
         "male",
         "kalyan",
         "student",
         "gt_8",
         "healthy",
         "'class 12'",
         "yes",
         "yes"
        ],
        [
         "16",
         "female",
         "srinagar",
         "student",
         "bt_7_8",
         "moderate",
         "be",
         "yes",
         "no"
        ],
        [
         "17",
         "male",
         "chennai",
         "student",
         "gt_8",
         "unhealthy",
         "bca",
         "no",
         "no"
        ],
        [
         "18",
         "female",
         "ludhiana",
         "student",
         "lt_5",
         "moderate",
         "'class 12'",
         "yes",
         "no"
        ],
        [
         "19",
         "female",
         "meerut",
         "student",
         "bt_7_8",
         "moderate",
         "m.ed",
         "yes",
         "yes"
        ],
        [
         "20",
         "female",
         "bhopal",
         "student",
         "bt_5_6",
         "moderate",
         "'class 12'",
         "yes",
         "yes"
        ],
        [
         "21",
         "female",
         "lucknow",
         "student",
         "gt_8",
         "unhealthy",
         "md",
         "yes",
         "yes"
        ],
        [
         "22",
         "male",
         "pune",
         "student",
         "gt_8",
         "unhealthy",
         "b.tech",
         "no",
         "no"
        ],
        [
         "23",
         "female",
         "surat",
         "student",
         "lt_5",
         "moderate",
         "llb",
         "no",
         "yes"
        ],
        [
         "24",
         "male",
         "ghaziabad",
         "student",
         "bt_5_6",
         "moderate",
         "bsc",
         "no",
         "no"
        ],
        [
         "25",
         "female",
         "chennai",
         "student",
         "lt_5",
         "unhealthy",
         "'class 12'",
         "yes",
         "no"
        ],
        [
         "26",
         "male",
         "kolkata",
         "student",
         "gt_8",
         "unhealthy",
         "m.pharm",
         "yes",
         "no"
        ],
        [
         "27",
         "female",
         "vasai-virar",
         "student",
         "bt_5_6",
         "moderate",
         "b.arch",
         "no",
         "yes"
        ],
        [
         "28",
         "female",
         "kanpur",
         "student",
         "lt_5",
         "moderate",
         "m.tech",
         "yes",
         "no"
        ],
        [
         "29",
         "male",
         "varanasi",
         "student",
         "gt_8",
         "unhealthy",
         "b.arch",
         "yes",
         "yes"
        ],
        [
         "30",
         "male",
         "varanasi",
         "student",
         "bt_7_8",
         "unhealthy",
         "b.com",
         "yes",
         "no"
        ],
        [
         "31",
         "male",
         "jaipur",
         "student",
         "bt_5_6",
         "healthy",
         "b.pharm",
         "yes",
         "yes"
        ],
        [
         "32",
         "male",
         "ghaziabad",
         "student",
         "bt_5_6",
         "unhealthy",
         "'class 12'",
         "no",
         "yes"
        ],
        [
         "33",
         "male",
         "agra",
         "student",
         "lt_5",
         "moderate",
         "mbbs",
         "yes",
         "yes"
        ],
        [
         "34",
         "male",
         "srinagar",
         "student",
         "lt_5",
         "healthy",
         "llm",
         "yes",
         "yes"
        ],
        [
         "35",
         "male",
         "vasai-virar",
         "student",
         "bt_5_6",
         "moderate",
         "ma",
         "no",
         "yes"
        ],
        [
         "36",
         "male",
         "srinagar",
         "student",
         "lt_5",
         "moderate",
         "'class 12'",
         "yes",
         "no"
        ],
        [
         "37",
         "male",
         "surat",
         "student",
         "lt_5",
         "healthy",
         "mbbs",
         "yes",
         "yes"
        ],
        [
         "38",
         "female",
         "nagpur",
         "student",
         "bt_5_6",
         "healthy",
         "msc",
         "yes",
         "no"
        ],
        [
         "39",
         "female",
         "kanpur",
         "student",
         "lt_5",
         "unhealthy",
         "'class 12'",
         "yes",
         "no"
        ],
        [
         "40",
         "male",
         "vasai-virar",
         "student",
         "gt_8",
         "healthy",
         "b.tech",
         "yes",
         "no"
        ],
        [
         "41",
         "male",
         "visakhapatnam",
         "student",
         "lt_5",
         "unhealthy",
         "mba",
         "yes",
         "no"
        ],
        [
         "42",
         "female",
         "vasai-virar",
         "student",
         "lt_5",
         "moderate",
         "bca",
         "yes",
         "yes"
        ],
        [
         "43",
         "female",
         "bangalore",
         "student",
         "bt_5_6",
         "healthy",
         "b.tech",
         "yes",
         "no"
        ],
        [
         "44",
         "female",
         "kalyan",
         "student",
         "lt_5",
         "moderate",
         "bsc",
         "no",
         "no"
        ],
        [
         "45",
         "male",
         "mumbai",
         "student",
         "gt_8",
         "moderate",
         "llb",
         "yes",
         "yes"
        ],
        [
         "46",
         "male",
         "vadodara",
         "student",
         "bt_7_8",
         "healthy",
         "b.arch",
         "yes",
         "yes"
        ],
        [
         "47",
         "female",
         "bhopal",
         "student",
         "lt_5",
         "unhealthy",
         "ma",
         "yes",
         "no"
        ],
        [
         "48",
         "female",
         "rajkot",
         "student",
         "bt_7_8",
         "healthy",
         "bca",
         "yes",
         "yes"
        ],
        [
         "49",
         "female",
         "ghaziabad",
         "student",
         "gt_8",
         "moderate",
         "b.arch",
         "yes",
         "no"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 22320
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>profession</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>dietary_habits</th>\n",
       "      <th>degree</th>\n",
       "      <th>suicidal_thoughts</th>\n",
       "      <th>family_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>jaipur</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>moderate</td>\n",
       "      <td>'class 12'</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>vadodara</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>moderate</td>\n",
       "      <td>b.arch</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>m.ed</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>bhopal</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>moderate</td>\n",
       "      <td>b.com</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>patna</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_5_6</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>b.com</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22315</th>\n",
       "      <td>male</td>\n",
       "      <td>kolkata</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>b.com</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22316</th>\n",
       "      <td>female</td>\n",
       "      <td>patna</td>\n",
       "      <td>student</td>\n",
       "      <td>lt_5</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>msc</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22317</th>\n",
       "      <td>male</td>\n",
       "      <td>lucknow</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>healthy</td>\n",
       "      <td>b.arch</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22318</th>\n",
       "      <td>female</td>\n",
       "      <td>kolkata</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_5_6</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>md</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22319</th>\n",
       "      <td>female</td>\n",
       "      <td>thane</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_5_6</td>\n",
       "      <td>healthy</td>\n",
       "      <td>b.ed</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22320 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender       city profession sleep_duration dietary_habits      degree  \\\n",
       "0        male     jaipur    student         bt_7_8       moderate  'class 12'   \n",
       "1        male   vadodara    student         bt_7_8       moderate      b.arch   \n",
       "2        male  ahmedabad    student         bt_7_8      unhealthy        m.ed   \n",
       "3        male     bhopal    student         bt_7_8       moderate       b.com   \n",
       "4        male      patna    student         bt_5_6      unhealthy       b.com   \n",
       "...       ...        ...        ...            ...            ...         ...   \n",
       "22315    male    kolkata    student         bt_7_8      unhealthy       b.com   \n",
       "22316  female      patna    student           lt_5      unhealthy         msc   \n",
       "22317    male    lucknow    student         bt_7_8        healthy      b.arch   \n",
       "22318  female    kolkata    student         bt_5_6      unhealthy          md   \n",
       "22319  female      thane    student         bt_5_6        healthy        b.ed   \n",
       "\n",
       "      suicidal_thoughts family_history  \n",
       "0                   yes             no  \n",
       "1                    no            yes  \n",
       "2                   yes            yes  \n",
       "3                   yes             no  \n",
       "4                    no             no  \n",
       "...                 ...            ...  \n",
       "22315               yes             no  \n",
       "22316               yes            yes  \n",
       "22317               yes            yes  \n",
       "22318               yes             no  \n",
       "22319                no            yes  \n",
       "\n",
       "[22320 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories = sleep_duration_cleanup_fn(updated_categories)\n",
    "updated_categories = sleep_duration_mapping_fn(updated_categories)\n",
    "updated_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34c76a",
   "metadata": {},
   "source": [
    "### Preprocessing Dietary Habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e75d8a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dietary_habits\n",
       "unhealthy    8265\n",
       "moderate     7898\n",
       "healthy      6149\n",
       "others          8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"dietary_habits\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a79ca",
   "metadata": {},
   "source": [
    "* This looks straight forward, we can OneHot/Ordinal encoder to encode them \n",
    "* Even here we can merge `other` with `unhealthy` since the sample size is very small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbf04e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dietary_habits_pipeline__dietary_habits_healthy',\n",
       "       'dietary_habits_pipeline__dietary_habits_moderate',\n",
       "       'dietary_habits_pipeline__dietary_habits_unhealthy'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function to map dietary habits 'other' value to unhealthy\n",
    "def dietary_habits_mapping_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy.loc[df_copy[\"dietary_habits\"] == \"others\",\"dietary_habits\"] = \"unhealthy\"\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "dietary_habits_mapping = FunctionTransformer(\n",
    "    dietary_habits_mapping_fn, feature_names_out=\"one-to-one\")\n",
    "\n",
    "\n",
    "def make_dietary_habits_pipeline_fn(encoding='onehot'):\n",
    "    steps = [\n",
    "        (\"default_cat_pipeline\", default_cat_pipeline),\n",
    "        (\"dietary_habits_mapping\", dietary_habits_mapping)\n",
    "    ]\n",
    "\n",
    "    if encoding == \"onehot\":\n",
    "        steps.append((\"encoder\", OneHotEncoder(\n",
    "            sparse_output=False, handle_unknown=\"ignore\")))\n",
    "    elif encoding == \"ordinal\":\n",
    "        steps.append((\"encoder\", OrdinalEncoder(categories=[[\n",
    "            \"unhealthy\", \"moderate\", \"healthy\"\n",
    "        ]], handle_unknown=\"use_encoded_value\", unknown_value=-1)))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid encoding type: choose 'onehot' or 'ordinal'\")\n",
    "    return Pipeline(steps=steps)\n",
    "\n",
    "preprocesing_dietary_habits = ColumnTransformer([(\n",
    "    \"dietary_habits_pipeline\", make_dietary_habits_pipeline_fn(encoding=\"onehot\"), [\n",
    "        \"dietary_habits\"]\n",
    ")])\n",
    "\n",
    "temp = preprocesing_dietary_habits.fit_transform(X_train)\n",
    "preprocesing_dietary_habits.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9a2d5",
   "metadata": {},
   "source": [
    "* Lets update the category values for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfe6ee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dietary_habits\n",
       "unhealthy    8273\n",
       "moderate     7898\n",
       "healthy      6149\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories = dietary_habits_mapping_fn(updated_categories)\n",
    "updated_categories[\"dietary_habits\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471fa596",
   "metadata": {},
   "source": [
    "### Preprocessing Degree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fa4534e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "degree\n",
       "'class 12'    4808\n",
       "b.ed          1487\n",
       "b.com         1193\n",
       "b.arch        1183\n",
       "bca           1132\n",
       "msc            968\n",
       "b.tech         931\n",
       "mca            830\n",
       "m.tech         816\n",
       "bhm            743\n",
       "bsc            719\n",
       "m.ed           672\n",
       "b.pharm        654\n",
       "m.com          590\n",
       "bba            563\n",
       "mbbs           562\n",
       "llb            529\n",
       "be             485\n",
       "m.pharm        478\n",
       "ba             477\n",
       "md             473\n",
       "mba            455\n",
       "ma             445\n",
       "phd            432\n",
       "llm            380\n",
       "me             143\n",
       "mhm            142\n",
       "others          30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"degree\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67944d60",
   "metadata": {},
   "source": [
    "* This is going to be a tricky one, but thanks to ChatGPT we have a dictionary mapping degree to field and level. \n",
    "* Here is the plan for the pipeline,\n",
    "    * Step 1: Clean the values which might have \"'\" around them .\n",
    "    * Step 2: Create two new fields degree_field and degree_level and update the values based on dictionary mapping below. We'll also use this for data exploration\n",
    "    * Step 3: Create a one hot encoding function degree_field\n",
    "    * Step 4: Create a generic encoding function (one hot or ordinal) for degree level (unknown < high_school < bachelor < master < doctorate). Anything else is -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33946f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_mapping_dict = {\n",
    "    \"class 12\":     {\"field\": \"school\",      \"level\": \"high_school\"},\n",
    "\n",
    "    # Commerce & Business\n",
    "    \"b.com\":        {\"field\": \"commerce\",    \"level\": \"bachelor\"},\n",
    "    \"m.com\":        {\"field\": \"commerce\",    \"level\": \"master\"},\n",
    "    \"bba\":          {\"field\": \"business\",    \"level\": \"bachelor\"},\n",
    "    \"mba\":          {\"field\": \"business\",    \"level\": \"master\"},\n",
    "\n",
    "    # Engineering & Tech\n",
    "    \"b.tech\":       {\"field\": \"engineering\", \"level\": \"bachelor\"},\n",
    "    \"be\":           {\"field\": \"engineering\", \"level\": \"bachelor\"},\n",
    "    \"b.arch\":       {\"field\": \"architecture\",\"level\": \"bachelor\"},\n",
    "    \"me\":           {\"field\": \"engineering\", \"level\": \"master\"},\n",
    "    \"m.tech\":       {\"field\": \"engineering\", \"level\": \"master\"},\n",
    "\n",
    "    # Science & CS\n",
    "    \"bsc\":          {\"field\": \"science\",     \"level\": \"bachelor\"},\n",
    "    \"msc\":          {\"field\": \"science\",     \"level\": \"master\"},\n",
    "    \"bca\":          {\"field\": \"computer_app\",\"level\": \"bachelor\"},\n",
    "    \"mca\":          {\"field\": \"computer_app\",\"level\": \"master\"},\n",
    "\n",
    "    # Education\n",
    "    \"b.ed\":         {\"field\": \"education\",   \"level\": \"bachelor\"},\n",
    "    \"m.ed\":         {\"field\": \"education\",   \"level\": \"master\"},\n",
    "\n",
    "    # Medical\n",
    "    \"mbbs\":         {\"field\": \"medical\",     \"level\": \"bachelor\"},\n",
    "    \"md\":           {\"field\": \"medical\",     \"level\": \"master\"},  # Technically PG, but aligned here\n",
    "    \"b.pharm\":      {\"field\": \"pharmacy\",    \"level\": \"bachelor\"},\n",
    "    \"m.pharm\":      {\"field\": \"pharmacy\",    \"level\": \"master\"},\n",
    "\n",
    "    # Law\n",
    "    \"llb\":          {\"field\": \"law\",         \"level\": \"bachelor\"},\n",
    "    \"llm\":          {\"field\": \"law\",         \"level\": \"master\"},\n",
    "\n",
    "    # Hospitality\n",
    "    \"bhm\":          {\"field\": \"hospitality\", \"level\": \"bachelor\"},\n",
    "    \"mhm\":          {\"field\": \"hospitality\", \"level\": \"master\"},\n",
    "\n",
    "    # Arts\n",
    "    \"ba\":           {\"field\": \"arts\",        \"level\": \"bachelor\"},\n",
    "    \"ma\":           {\"field\": \"arts\",        \"level\": \"master\"},\n",
    "\n",
    "    # Research\n",
    "    \"phd\":          {\"field\": \"research\",    \"level\": \"doctorate\"},\n",
    "\n",
    "    # Other\n",
    "    \"others\":       {\"field\": \"unknown\",     \"level\": \"unknown\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f894df73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['degree_pipeline__encode_degree_field__degree_field_architecture',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_arts',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_business',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_commerce',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_computer_app',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_education',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_engineering',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_hospitality',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_law',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_medical',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_pharmacy',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_research',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_school',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_science',\n",
       "       'degree_pipeline__encode_degree_field__degree_field_unknown',\n",
       "       'degree_pipeline__encode_degree_level__degree_level_bachelor',\n",
       "       'degree_pipeline__encode_degree_level__degree_level_doctorate',\n",
       "       'degree_pipeline__encode_degree_level__degree_level_high_school',\n",
       "       'degree_pipeline__encode_degree_level__degree_level_master',\n",
       "       'degree_pipeline__encode_degree_level__degree_level_unknown'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function to clean up degree column\n",
    "def degree_cleanup_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\n",
    "            \"degree_cleanup_fn : Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"degree\"] = df_copy[\"degree\"].str.strip(\"'\")\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "degree_cleanup = FunctionTransformer(\n",
    "    degree_cleanup_fn, feature_names_out=\"one-to-one\")\n",
    "\n",
    "\n",
    "def degree_mapping_feature_names(function_transformer, feature_names_in):\n",
    "    features_out = feature_names_in.tolist()\n",
    "    features_out.extend([\"degree_field\", \"degree_level\"])\n",
    "    return features_out\n",
    "\n",
    "# helper funtion to map degree to degree_field and degree_level\n",
    "def map_field(val):\n",
    "    return degree_mapping_dict.get(val, {}).get(\"field\", \"unknown\")\n",
    "\n",
    "\n",
    "def map_level(val):\n",
    "    return degree_mapping_dict.get(val, {}).get(\"level\", \"unknown\")\n",
    "\n",
    "\n",
    "def degree_mapping_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"degree_mapping_fn: Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"degree_field\"] = df_copy[\"degree\"].map(map_field)\n",
    "    df_copy[\"degree_level\"] = df_copy[\"degree\"].map(map_level)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "degree_mapping = FunctionTransformer(\n",
    "    degree_mapping_fn, feature_names_out=degree_mapping_feature_names)\n",
    "\n",
    "# helper function to create a column transformer to encode degree_field and degree_level fields.\n",
    "\n",
    "\n",
    "def make_degree_encoder(encoding=\"onehot\"):\n",
    "    degree_level_encoder = OneHotEncoder(\n",
    "        handle_unknown=\"ignore\", sparse_output=False)\n",
    "    \n",
    "    if encoding == \"ordinal\":\n",
    "        degree_level_encoder = OrdinalEncoder(categories=[[\n",
    "            \"unknown\", \"high_school\", \"bachelor\", \"master\", \"doctorate\"\n",
    "        ]], handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        (\"encode_degree_field\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"degree_field\"]),\n",
    "        (\"encode_degree_level\", degree_level_encoder, [\"degree_level\"])\n",
    "    ])\n",
    "\n",
    "\n",
    "# testing basic pipeline\n",
    "degree_pipeline = Pipeline([\n",
    "    (\"default_cat_pipeline\", default_cat_pipeline),\n",
    "    (\"cleanup\", degree_cleanup),\n",
    "    (\"mapping\", degree_mapping),\n",
    "    (\"encode_degree\",make_degree_encoder())\n",
    "])\n",
    "\n",
    "preprocessing_degree = ColumnTransformer([\n",
    "    (\"degree_pipeline\", degree_pipeline, [\"degree\"])\n",
    "])\n",
    "temp = preprocessing_degree.fit_transform(X_train)\n",
    "preprocessing_degree.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc53150f",
   "metadata": {},
   "source": [
    "* Lets cleanup and create the degree mapping columns for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bd0ac00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "profession",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sleep_duration",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dietary_habits",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "degree",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "suicidal_thoughts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "family_history",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "degree_field",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "degree_level",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "73bc45cd-dfd4-4404-8ace-2c7f7c0f3a83",
       "rows": [
        [
         "0",
         "male",
         "jaipur",
         "student",
         "bt_7_8",
         "moderate",
         "class 12",
         "yes",
         "no",
         "school",
         "high_school"
        ],
        [
         "1",
         "male",
         "vadodara",
         "student",
         "bt_7_8",
         "moderate",
         "b.arch",
         "no",
         "yes",
         "architecture",
         "bachelor"
        ],
        [
         "2",
         "male",
         "ahmedabad",
         "student",
         "bt_7_8",
         "unhealthy",
         "m.ed",
         "yes",
         "yes",
         "education",
         "master"
        ],
        [
         "3",
         "male",
         "bhopal",
         "student",
         "bt_7_8",
         "moderate",
         "b.com",
         "yes",
         "no",
         "commerce",
         "bachelor"
        ],
        [
         "4",
         "male",
         "patna",
         "student",
         "bt_5_6",
         "unhealthy",
         "b.com",
         "no",
         "no",
         "commerce",
         "bachelor"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>profession</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>dietary_habits</th>\n",
       "      <th>degree</th>\n",
       "      <th>suicidal_thoughts</th>\n",
       "      <th>family_history</th>\n",
       "      <th>degree_field</th>\n",
       "      <th>degree_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>jaipur</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>moderate</td>\n",
       "      <td>class 12</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>school</td>\n",
       "      <td>high_school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>vadodara</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>moderate</td>\n",
       "      <td>b.arch</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>architecture</td>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>m.ed</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>education</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>bhopal</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_7_8</td>\n",
       "      <td>moderate</td>\n",
       "      <td>b.com</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>commerce</td>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>patna</td>\n",
       "      <td>student</td>\n",
       "      <td>bt_5_6</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>b.com</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>commerce</td>\n",
       "      <td>bachelor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender       city profession sleep_duration dietary_habits    degree  \\\n",
       "0   male     jaipur    student         bt_7_8       moderate  class 12   \n",
       "1   male   vadodara    student         bt_7_8       moderate    b.arch   \n",
       "2   male  ahmedabad    student         bt_7_8      unhealthy      m.ed   \n",
       "3   male     bhopal    student         bt_7_8       moderate     b.com   \n",
       "4   male      patna    student         bt_5_6      unhealthy     b.com   \n",
       "\n",
       "  suicidal_thoughts family_history  degree_field degree_level  \n",
       "0               yes             no        school  high_school  \n",
       "1                no            yes  architecture     bachelor  \n",
       "2               yes            yes     education       master  \n",
       "3               yes             no      commerce     bachelor  \n",
       "4                no             no      commerce     bachelor  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories = degree_cleanup_fn(updated_categories)\n",
    "updated_categories = degree_mapping_fn(updated_categories)\n",
    "updated_categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2171e1",
   "metadata": {},
   "source": [
    "### Preprocessing Suicidal Thoughts Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83a6d0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "suicidal_thoughts\n",
       "yes    14133\n",
       "no      8187\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"suicidal_thoughts\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720286f6",
   "metadata": {},
   "source": [
    "* This seems straight forward, and data seems clean enough. We can simply one hot encode this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f4e3c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['suicidal_thoughts_pipeline__suicidal_thoughts_no',\n",
       "       'suicidal_thoughts_pipeline__suicidal_thoughts_yes'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicidal_thoughts_pipeline = Pipeline([\n",
    "    (\"default_cat_pipeline\", default_cat_pipeline),\n",
    "    (\"suididal_thoughts_encoding\", OneHotEncoder(\n",
    "        handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessing_suicidal_thoughts = ColumnTransformer(\n",
    "    [(\n",
    "        \"suicidal_thoughts_pipeline\", suicidal_thoughts_pipeline,[\"suicidal_thoughts\"]\n",
    "    )]\n",
    ")\n",
    "\n",
    "temp = preprocessing_suicidal_thoughts.fit_transform(X_train)\n",
    "preprocessing_suicidal_thoughts.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ffb60",
   "metadata": {},
   "source": [
    "### Preprocessing Family History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cfe3370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family_history\n",
       "no     11517\n",
       "yes    10803\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"family_history\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1de7fb",
   "metadata": {},
   "source": [
    "* Even this seems straight forward a simple one hot encoding should make this column ready for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b64d6cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['family_history_pipeline__family_history_no',\n",
       "       'family_history_pipeline__family_history_yes'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family_history_pipeline = Pipeline([\n",
    "    (\"default_cat_pipeline\", default_cat_pipeline),\n",
    "    (\"family_history_encoding\", OneHotEncoder(\n",
    "        handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessing_family_history = ColumnTransformer(\n",
    "    [(\n",
    "        \"family_history_pipeline\", family_history_pipeline,[\"family_history\"]\n",
    "    )]\n",
    ")\n",
    "\n",
    "temp = preprocessing_family_history.fit_transform(X_train)\n",
    "preprocessing_family_history.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad6047",
   "metadata": {},
   "source": [
    "### Preprocessing 'city' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78dc2fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "kalyan                  1284\n",
       "srinagar                1073\n",
       "hyderabad               1063\n",
       "vasai-virar             1042\n",
       "lucknow                  943\n",
       "thane                    910\n",
       "kolkata                  890\n",
       "agra                     864\n",
       "ludhiana                 848\n",
       "surat                    842\n",
       "jaipur                   840\n",
       "patna                    823\n",
       "visakhapatnam            763\n",
       "pune                     751\n",
       "bhopal                   748\n",
       "ahmedabad                748\n",
       "chennai                  707\n",
       "meerut                   660\n",
       "rajkot                   633\n",
       "bangalore                625\n",
       "delhi                    602\n",
       "ghaziabad                588\n",
       "mumbai                   563\n",
       "vadodara                 561\n",
       "varanasi                 550\n",
       "nagpur                   533\n",
       "indore                   519\n",
       "kanpur                   493\n",
       "nashik                   452\n",
       "faridabad                381\n",
       "harsha                     2\n",
       "bhavna                     2\n",
       "saanvi                     2\n",
       "city                       2\n",
       "khaziabad                  1\n",
       "m.com                      1\n",
       "3.0                        1\n",
       "harsh                      1\n",
       "mihir                      1\n",
       "'less delhi'               1\n",
       "gaurav                     1\n",
       "nalyan                     1\n",
       "nandini                    1\n",
       "'less than 5 kalyan'       1\n",
       "reyansh                    1\n",
       "m.tech                     1\n",
       "mira                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_categories[\"city\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc5304",
   "metadata": {},
   "source": [
    "* So city column needs some clearning, \n",
    "    * There might be cities with special characters \"'\" that needs to be cleaned up.\n",
    "    * There are some values which are obviously not a city but rather distances, person names and education degree names. To fix this we'll use the master city dataset that has verified city names and lat/long info that we'll add as additional columns\n",
    "    * We'll also add a `is_valid_city` flag and for in valid city names we'll use `Nagpur` as default name and default lat/long as it is considered to be the geographical center of India. \n",
    "    * We don't need encoding for the city but rather we'll use cluster similarity to find the similarity between clusters. We **might** do that after some data exploration.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fde8593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ascii_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "long",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "12886b8d-1d9c-4cc4-ab71-e83c494ec871",
       "rows": [
        [
         "0",
         "#100 bed and breakfast",
         "#100 bed and breakfast",
         "12.98332",
         "77.58427"
        ],
        [
         "1",
         "10 calangute",
         "10 calangute",
         "15.54244",
         "73.76279"
        ],
        [
         "2",
         "100 feet hospital",
         "100 feet hospital",
         "19.38609",
         "72.82558"
        ],
        [
         "3",
         "12th avenue hotel",
         "12th avenue hotel",
         "12.97044",
         "77.64617"
        ],
        [
         "4",
         "1589 city mark hotel",
         "1589 city mark hotel",
         "28.46348",
         "77.03176"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ascii_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#100 bed and breakfast</td>\n",
       "      <td>#100 bed and breakfast</td>\n",
       "      <td>12.98332</td>\n",
       "      <td>77.58427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 calangute</td>\n",
       "      <td>10 calangute</td>\n",
       "      <td>15.54244</td>\n",
       "      <td>73.76279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100 feet hospital</td>\n",
       "      <td>100 feet hospital</td>\n",
       "      <td>19.38609</td>\n",
       "      <td>72.82558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12th avenue hotel</td>\n",
       "      <td>12th avenue hotel</td>\n",
       "      <td>12.97044</td>\n",
       "      <td>77.64617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1589 city mark hotel</td>\n",
       "      <td>1589 city mark hotel</td>\n",
       "      <td>28.46348</td>\n",
       "      <td>77.03176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name              ascii_name       lat      long\n",
       "0  #100 bed and breakfast  #100 bed and breakfast  12.98332  77.58427\n",
       "1            10 calangute            10 calangute  15.54244  73.76279\n",
       "2       100 feet hospital       100 feet hospital  19.38609  72.82558\n",
       "3       12th avenue hotel       12th avenue hotel  12.97044  77.64617\n",
       "4    1589 city mark hotel    1589 city mark hotel  28.46348  77.03176"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load the master city data\n",
    "## read master city list\n",
    "master_city_list = pd.read_csv(Path(data_dir,\"detailed_in.csv\"))\n",
    "\n",
    "\n",
    "## convert the city names to lower case\n",
    "# master_city_list[\"name\"] = master_city_list[\"name\"].str.strip().str.lower()\n",
    "# master_city_list[\"ascii_name\"] = master_city_list[\"ascii_name\"].str.strip().str.lower()\n",
    "\n",
    "# ## unicode normalization\n",
    "# master_city_list[\"name\"] = master_city_list[\"name\"].map(lambda ct: unicodedata.normalize(\"NFKD\",ct).encode(\"ascii\",\"ignore\").decode())\n",
    "# master_city_list[\"ascii_name\"] = master_city_list[\"ascii_name\"].map(lambda ct: unicodedata.normalize(\"NFKD\",ct).encode(\"ascii\",\"ignore\").decode())\n",
    "\n",
    "# X_train[\"city\"].map(lambda ct: unicodedata.normalize(\"NFKD\",ct).encode(\"ascii\",\"ignore\").decode())\n",
    "# master_cities = master_city_list[\"ascii_name\"].str.strip().str.lower().to_list()\n",
    "# master_cities[:5]\n",
    "master_city_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bd90b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ascii_name\n",
       "#100 bed and breakfast    1\n",
       "narayanpur mardan         1\n",
       "narayanpur majhari        1\n",
       "narayanpur main canal     1\n",
       "narayanpur mafi           1\n",
       "                         ..\n",
       "gyadal gondi              1\n",
       "gya                       1\n",
       "gwinai                    1\n",
       "gwilani                   1\n",
       "zuvvigunta                1\n",
       "Name: count, Length: 407781, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_city_list[\"ascii_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "afcbfba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to clean up city column and remove special characters\n",
    "def city_cleanup_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\n",
    "            \"degree_cleanup_fn : Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"city\"] = df_copy[\"city\"].str.strip(\"'\")\n",
    "    return df_copy\n",
    "\n",
    "city_cleanup = FunctionTransformer(city_cleanup_fn, feature_names_out=\"one-to-one\")\n",
    "\n",
    "# helper function that maps city names to default values of is_valid_city = 0, lat/long of Nagpur\n",
    "def city_mapping_feature_names(function_transformer, feature_names_in):\n",
    "    features_out = feature_names_in.tolist()\n",
    "    features_out.extend([\"is_valid_city\",\"lat\", \"long\"])\n",
    "    return features_out\n",
    "\n",
    "def city_mapping_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\n",
    "            \"degree_cleanup_fn : Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"is_valid_city\"] = 0\n",
    "    df_copy[\"lat\"] = 21.122615\n",
    "    df_copy[\"long\"] = 79.041124\n",
    "    return df_copy\n",
    "\n",
    "city_mapping = FunctionTransformer(city_mapping_fn, feature_names_out=city_mapping_feature_names)\n",
    "\n",
    "# helper function that compares and verifies the city name and if its a valid city then updates the lat/long value\n",
    "def map_city_data(city_name):\n",
    "    ## search for city name in master city lsit\n",
    "    city_data = master_city_list.loc[master_city_list[\"name\"] == city_name]\n",
    "    ## if city exists then return valid info\n",
    "    if city_data.shape[0] > 0:\n",
    "        return (1, city_data[\"lat\"].values[0],city_data[\"long\"].values[0])\n",
    "    ## if city doesn't exist the mark it as invalid and return default info\n",
    "    return 0,21.122615,79.041124\n",
    "    \n",
    "\n",
    "def city_verification_fn(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\n",
    "            \"degree_cleanup_fn : Input must be a pandas DataFrame\")\n",
    "    df_copy = df.copy()\n",
    "    unique_cities = df_copy[\"city\"].unique()\n",
    "    for unique_city in unique_cities:\n",
    "        is_valid_city,lat,long = map_city_data(unique_city)\n",
    "        df_copy.loc[df_copy[\"city\"] == unique_city, \"is_valid_city\"] = is_valid_city\n",
    "        df_copy.loc[df_copy[\"city\"] == unique_city, \"lat\"] = lat\n",
    "        df_copy.loc[df_copy[\"city\"] == unique_city, \"long\"] = long\n",
    "    return df_copy\n",
    "\n",
    "city_verification = FunctionTransformer(city_verification_fn, feature_names_out=\"one-to-one\")\n",
    "\n",
    "# function to fuzzy match invalid cities to master city list.\n",
    "# from rapidfuzz import process, fuzz,utils\n",
    "\n",
    "# unique_master_cites = master_city_list[\"name\"].values\n",
    "# def map_fuzzy_matched_city(city_name):\n",
    "#     matched_list = process.extract(city_name, unique_master_cites, scorer=fuzz.QRatio,limit=1)\n",
    "#     match,score,_ = matched_list[0]\n",
    "#     print(city_name, match,score)\n",
    "\n",
    "# def fuzzy_city_mapper_fn(df):\n",
    "#     if not isinstance(df, pd.DataFrame):\n",
    "#         raise ValueError(\n",
    "#             \"degree_cleanup_fn : Input must be a pandas DataFrame\")\n",
    "#     df_copy = df.copy()\n",
    "#     ## only focuses on invalid city\n",
    "#     unique_cities = df_copy.loc[df_copy[\"is_valid_city\"] == 0,\"city\"].unique()\n",
    "#     for unique_city in unique_cities:\n",
    "#         map_fuzzy_matched_city(unique_city)\n",
    "#     return df_copy\n",
    "\n",
    "# fuzzy_city_mapping = FunctionTransformer(fuzzy_city_mapper_fn, feature_names_out=\"one-to-one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c05a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_pipeline = Pipeline([\n",
    "    (\"default_cat_pipeline\", default_cat_pipeline),\n",
    "    (\"city_cleanup\", city_cleanup),\n",
    "    (\"city_mapping\", city_mapping),\n",
    "    (\"city_verification\", city_verification),\n",
    "    # (\"fuzzy_city_mapping\", fuzzy_city_mapping)\n",
    "])\n",
    "\n",
    "preprocessing_city = ColumnTransformer([\n",
    "    (\"city_pipeline\", city_pipeline, [\"city\"])\n",
    "])\n",
    "\n",
    "\n",
    "temp = preprocessing_city.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33e250bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city_pipeline__is_valid_city\n",
       "1    20634\n",
       "0     1686\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.DataFrame(temp, columns=preprocessing_city.get_feature_names_out())\n",
    "temp_df[\"city_pipeline__is_valid_city\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7da134a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.170979936027916"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(temp_df.loc[temp_df[\"city_pipeline__is_valid_city\"] == 0].shape[0]/temp_df.loc[temp_df[\"city_pipeline__is_valid_city\"] == 1].shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ec9e9",
   "metadata": {},
   "source": [
    "* So we still have 8% of data with invalid cities. For now we've decided to keep it as it is and experiment with ML models to see how this affects the training.\n",
    "* For invalid cities we have a flag indicating whether the cities are valid or invalid, and we have lat/long defaulting to Nagpur. \n",
    "* Next step would be to explore non-categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ad0d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
