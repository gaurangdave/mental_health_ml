{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bbcd855",
   "metadata": {},
   "source": [
    "# Training & Evaluation\n",
    "* We are going to break down training and evaluation into multiple notebooks, one for each algorithm that we train and evalutate. \n",
    "* In this first notebook, we'll create baseline models to get the predictions based on `stratified` and `most frequent` classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb6a5d",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8899b25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/gaurangdave/workspace/mental_health_ml/venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/gaurangdave/workspace/mental_health_ml/venv/lib/python3.12/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/gaurangdave/workspace/mental_health_ml/venv/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/gaurangdave/workspace/mental_health_ml/venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/gaurangdave/workspace/mental_health_ml/venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f967ba",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817a38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "# Build an absolute path from this notebook's parent directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.utils import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6915b8",
   "metadata": {},
   "source": [
    "## Initialize Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a7ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = Path(\"..\", \"data/\")\n",
    "models_root_dir = Path(\"..\", \"models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c57b2f",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59abdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(Path(data_root_dir,\"X_train.csv\"))\n",
    "y_train = pd.read_csv(Path(data_root_dir,\"y_train.csv\"))\n",
    "X_test = pd.read_csv(Path(data_root_dir,\"X_test.csv\"))\n",
    "y_test = pd.read_csv(Path(data_root_dir,\"y_test.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34586776",
   "metadata": {},
   "source": [
    "## BaseLine Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69708a3",
   "metadata": {},
   "source": [
    "### Stratified Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e57447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified Prediction - Recall: 0.5936\n",
      "Stratified Prediction - Precision: 0.5918\n",
      "Weighted F1: 0.5927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score,precision_recall_curve\n",
    "\n",
    "\n",
    "dummy_stratified = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy_stratified.fit(X_train,y_train)\n",
    "\n",
    "## predict and evaulate\n",
    "stratified_predictions = dummy_stratified.predict(X_test)\n",
    "stratified_recall = recall_score(y_test, stratified_predictions)\n",
    "stratified_precision = precision_score(y_test, stratified_predictions)\n",
    "stratified_f1 = f1_score(y_test, stratified_predictions)\n",
    "print(f\"Stratified Prediction - Recall: {stratified_recall:.4f}\")\n",
    "print(f\"Stratified Prediction - Precision: {stratified_precision:.4f}\")\n",
    "print(f\"Weighted F1: {stratified_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9d444",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Our `0.59` recall score tells us that out of all positive cases our model was able to identify 59% of cases,i.e it misdiagnoized 41% cases where the students were actually depressed.\n",
    "* `0.59` Precision score tells us that out of all the postive predictions only 59% were actually positive and 41% were false positive, i.e. 41% of the students will need unnecessary worry, follow-up and resource allocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b115fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequent Prediction - Recall: 1.0000\n",
      "Most Frequent Prediction - Precision: 0.5856\n",
      "Weighted F1: 0.7386\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dummy_most_frequent = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "dummy_most_frequent.fit(X_train,y_train)\n",
    "\n",
    "## predict and evaulate\n",
    "most_frequent_predictions = dummy_most_frequent.predict(X_test)\n",
    "most_frequent_recall = recall_score(y_test, most_frequent_predictions)\n",
    "most_frequent_precision = precision_score(y_test, most_frequent_predictions)\n",
    "most_frequent_f1 = f1_score(y_test, most_frequent_predictions)\n",
    "print(f\"Most Frequent Prediction - Recall: {most_frequent_recall:.4f}\")\n",
    "print(f\"Most Frequent Prediction - Precision: {most_frequent_precision:.4f}\")\n",
    "print(f\"Weighted F1: {most_frequent_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb01e3",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Our `1` recall score tells us that out of all positive cases our model was able to identify 100% of cases,which is great because our model didn't misdiagnoize any actually depressed students.\n",
    "* `0.58` Precision score tells us that out of all the postive predictions only 58% were actually positive and 42% were false positive, i.e. 42% of the students will need unnecessary worry, follow-up and resource allocation. \n",
    "* Even though recall score of 1 is desirable, we want to aim for better F1 score, i.e better balance between recall and precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2a7de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
